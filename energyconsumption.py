# -*- coding: utf-8 -*-
"""EnergyConsumption.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZyUqJEjmILPzSU65vilkh1TMAdO-KU7Y
"""

import pandas as pd

# Load the dataset
df = pd.read_csv('/content/World Energy Consumption.csv')

# Display the first few rows of the dataset
print(df.head())

# Display information about the dataset
print(df.info())

# Summary statistics
print(df.describe())



# Check for missing values
print(df.isnull().sum())

# Select a subset of numerical columns
selected_numerical_columns = df.select_dtypes(include=[np.number]).columns[:5]  # Select first 5 numerical columns

# Plot boxplots for the selected numerical columns
plt.figure(figsize=(8, 8))
sns.boxplot(data=df[selected_numerical_columns], orient='h', fliersize=3)
plt.xlabel('Values')
plt.title('Boxplot of Selected Numerical Columns')
plt.show()

df.fillna(df.mode().iloc[0], inplace=True)

df.head()

values_in_column = df['country']
print(values_in_column)

import matplotlib.pyplot as plt
import seaborn as sns

# Select a subset of numerical columns
selected_numerical_columns = df.select_dtypes(include=[np.number]).columns[:5]  # Select first 5 numerical columns

# Calculate quartiles, IQR, lower and upper bounds for selected numerical columns
Q1 = df[selected_numerical_columns].quantile(0.25)
Q3 = df[selected_numerical_columns].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter outliers for each selected numerical column
for col in selected_numerical_columns:
    df = df[(df[col] >= lower_bound[col]) & (df[col] <= upper_bound[col])]

# Visualize the filtered dataset with boxplot
plt.figure(figsize=(6, 6))
sns.boxplot(data=df[selected_numerical_columns], orient='h', fliersize=3)
plt.xlabel('Values')
plt.title('Boxplot of Selected Numerical Columns')
plt.show()

# Select a subset of numerical variables
selected_numerical_columns = df.select_dtypes(include=[np.number]).columns[:5]  # Select first 5 numerical columns

# Plot histograms for the selected numerical variables
df[selected_numerical_columns].hist(figsize=(12, 8), bins=20, layout=(2, 3))
plt.tight_layout()
plt.show()

# Box plot for selected numerical variables
plt.figure(figsize=(6, 6))
sns.boxplot(data=df[selected_numerical_columns])
plt.xticks(rotation=45)
plt.show()

# Calculate summary statistics for numerical variables
summary_statistics = df.describe()

# Display summary statistics
print(summary_statistics)

# Select only numerical columns
numeric_df = df.select_dtypes(include=[np.number])

# Calculate correlation matrix
correlation_matrix = numeric_df.corr()

# Set threshold for correlation values
threshold = 0.5

# Filter correlations below the threshold
correlation_matrix_filtered = correlation_matrix[(correlation_matrix > threshold) | (correlation_matrix < -threshold)]

# Visualize filtered correlation matrix as a heatmap
plt.figure(figsize=(8, 10))
sns.heatmap(correlation_matrix_filtered, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix (Thresholded)')
plt.show()

# Perform one-way ANOVA
import scipy.stats as stats
f_statistic, p_value = stats.f_oneway(df[df['population'] == 'Afghanistan']['year'],
                                      df[df['population'] == 'Trinidad']['year'],
                                      df[df['population'] == 'Tobago']['year'])

# Print results
print("F-statistic:", f_statistic)
print("p-value:", p_value)

# Interpret results
alpha = 0.05
if p_value < alpha:
    print("Reject the null hypothesis: There is a significant difference in performance across different populations.")
else:
    print("Fail to reject the null hypothesis: There is no significant difference in performance across different populations.")

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Step 2: Prepare the Data
# Assuming 'X' contains predictor variables and 'y' contains the target variable
X = df[['gdp', 'biofuel_cons_change_pct', 'biofuel_cons_change_twh']]
y = df['population']

# Step 3: Split the Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Train the Model
model = LinearRegression()
model.fit(X_train, y_train)

# Step 5: Evaluate the Model
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)

# Step 6: Interpret the Results
coefficients = model.coef_
intercept = model.intercept_
print("Coefficients:", coefficients)
print("Intercept:", intercept)

#population	gdp	biofuel_cons_change_pct	biofuel_cons_change_twh	biofuel_cons_per_capita	biofuel_consumption

from sklearn.metrics import r2_score
import numpy as np

# Calculate R-squared
r_squared = r2_score(y_test, y_pred)

# Calculate adjusted R-squared
n = len(X_test)  # Number of samples in the testing set
p = X_test.shape[1]  # Number of predictor variables
adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)

# Calculate root mean squared error (RMSE)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

# Print evaluation metrics
print("R-squared:", r_squared)
print("Adjusted R-squared:", adjusted_r_squared)
print("RMSE:", rmse)

# Assuming 'model' is the trained multiple linear regression model

# Get the coefficients (slopes) and intercept (bias) from the model
coefficients = model.coef_
intercept = model.intercept_

# Print the coefficients
print("Intercept (Bias):", intercept)
for i, coef in enumerate(coefficients):
    print("Coefficient for predictor variable", i+1, ":", coef)

# Interpret the coefficients
print("\nInterpretation:")
print("The intercept represents the expected value of the target variable when all predictor variables are zero.")

for i, coef in enumerate(coefficients):
    print("For predictor variable", i+1, ":")
    if coef > 0:
        print("- A one-unit increase in this variable is associated with an increase of", coef, "units in the target variable.")
    elif coef < 0:
        print("- A one-unit increase in this variable is associated with a decrease of", abs(coef), "units in the target variable.")
    else:
        print("- This variable has no effect on the target variable.")

"""Split the dataset into training and testing sets."""

from sklearn.model_selection import train_test_split

X = df[['gdp', 'biofuel_cons_change_pct', 'biofuel_cons_change_twh']]
y = df['population']

# Split the dataset into training and testing sets (e.g., 80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Print the shapes of the training and testing sets to verify the split
print("Training set shape (X):", X_train.shape)
print("Testing set shape (X):", X_test.shape)
print("Training set shape (y):", y_train.shape)
print("Testing set shape (y):", y_test.shape)

"""Train the regression model on the training set and evaluate its performance on the
testing set
"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error

# 1. Import the regression model (already imported in previous steps)

# 2. Fit the model to the training data
model = LinearRegression()
model.fit(X_train, y_train)

# 3. Make predictions on the testing data
y_pred = model.predict(X_test)

# 4. Evaluate the performance of the model
r_squared = r2_score(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred, squared=False)  # RMSE (Root Mean Squared Error)

# Print evaluation metrics
print("R-squared:", r_squared)
print("RMSE:", rmse)

"""Use cross-validation techniques to assess the model's robustness and generalization
ability.

"""

from sklearn.model_selection import cross_val_score

# Define the regression model (e.g., LinearRegression)
model = LinearRegression()

# Perform k-fold cross-validation (e.g., k=5)
cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')  # Use R-squared as the evaluation metric

# Print cross-validation scores
print("Cross-Validation R-squared scores:", cv_scores)
print("Mean R-squared:", np.mean(cv_scores))

"""Summarize key findings from the analysis.

"""

# 1. Regression Model Performance
print("Regression Model Performance:")
print("R-squared:", r_squared)
print("RMSE:", rmse)
print("\n")

# 2. Predictor Variables Impact
print("Predictor Variables Impact:")
print("Intercept (Bias):", intercept)
for i, coef in enumerate(coefficients):
    print("Coefficient for predictor variable", i+1, ":", coef)
print("\n")

# 3. Cross-Validation Results
print("Cross-Validation Results:")
print("Cross-Validation R-squared scores:", cv_scores)
print("Mean R-squared:", np.mean(cv_scores))
print("\n")

# 4. Further Analysis (if applicable)
print("Further Analysis:")
print("Consider exploring interactions between predictor variables, additional features, or alternative models.")





